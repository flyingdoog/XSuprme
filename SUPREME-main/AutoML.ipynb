{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c534fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPREME is setting up!\n"
     ]
    }
   ],
   "source": [
    "from lib import module\n",
    "import time\n",
    "import os, itertools\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import statistics\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import errno\n",
    "import warnings\n",
    "\n",
    "base_path = ''\n",
    "feature_networks_integration = ['clinical', 'cna', 'exp','coe','met','mut'] # datatypes to concatanate node features from\n",
    "learning_rate = 0.001\n",
    "hid_size = 128\n",
    "\n",
    "# optimize for optional feature selection of node features\n",
    "feature_selection_per_network = [False, False, False,False, False, False]\n",
    "top_features_per_network = [50, 50, 50,50,50,50]\n",
    "optional_feat_selection = False\n",
    "boruta_runs = 100\n",
    "boruta_top_features = 50\n",
    "\n",
    "\n",
    "# fixed\n",
    "max_epochs = 500\n",
    "min_epochs = 200\n",
    "patience = 30\n",
    "\n",
    "# fixed to get the same results from the tool each time\n",
    "random_state = 404\n",
    "\n",
    "# SUPREME run\n",
    "print('SUPREME is setting up!')\n",
    "\n",
    "dataset_name = 'full_data'\n",
    "\n",
    "path = base_path + \"data/\" + dataset_name\n",
    "if not os.path.exists(path):\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), path)\n",
    "        \n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "# node_networks = ['exp','coe','met'] # datatypes to use networks from\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8499366e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use pre-defined split\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "data_path_node =  base_path + 'data/' + dataset_name +'/'\n",
    "run_name = 'SUPREME_'+  dataset_name + '_results'\n",
    "save_path = base_path + run_name + '/'\n",
    "\n",
    "if not os.path.exists(base_path + run_name):\n",
    "    os.makedirs(base_path + run_name + '/')\n",
    "\n",
    "file = base_path + 'data/' + dataset_name +'/labels.pkl'\n",
    "with open(file, 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "file = base_path + 'data/' + dataset_name + '/mask_values.pkl'\n",
    "if os.path.exists(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        train_valid_idx, test_idx = pickle.load(f)\n",
    "    print('use pre-defined split')\n",
    "else:\n",
    "    train_valid_idx, test_idx= train_test_split(np.arange(len(labels)), test_size=0.20, shuffle=True, stratify=labels)\n",
    "    print('use random split')\n",
    "start = time.time()\n",
    "\n",
    "    \n",
    "x_lists = []\n",
    "for netw in feature_networks_integration:\n",
    "    file = base_path + 'data/' + dataset_name +'/'+ netw +'.pkl'\n",
    "    with open(file, 'rb') as f:\n",
    "        feat = pickle.load(f)\n",
    "        values = feat.values\n",
    "        x_lists.append(values)\n",
    "        \n",
    "new_x = np.concatenate(x_lists,-1)\n",
    "scaler = StandardScaler()\n",
    "scaled_new_x = scaler.fit_transform(new_x)\n",
    "new_x = torch.tensor(scaled_new_x,dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "\n",
    "train_idx,valid_idx = train_test_split(train_valid_idx,test_size=0.2)\n",
    "train_mask = np.array([i in set(train_idx) for i in range(new_x.shape[0])])\n",
    "valid_mask = np.array([i in set(valid_idx) for i in range(new_x.shape[0])])\n",
    "test_mask = np.array([i in set(test_idx) for i in range(new_x.shape[0])])\n",
    "y_test = pd.DataFrame(labels[test_mask].cpu().numpy()).values.ravel()\n",
    "\n",
    "in_size = new_x.shape[1]\n",
    "out_size = torch.unique(labels).shape[0]\n",
    "new_x = new_x.cpu().numpy()\n",
    "labels = labels.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27448e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2023-10-26 22:52:34,176:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-10-26 22:52:35,168:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "[WARNING] [2023-10-26 22:52:35,588:Client-EnsembleBuilder] No runs were available to build an ensemble from\n",
      "Validation Accuracy: 0.92\n",
      "Test Accuracy: 0.85\n",
      "{2: {'model_id': 2, 'rank': 1, 'cost': 0.2417582417582418, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8cd895b5e0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8ad70ecaf0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8ad70ecb80>, 'sklearn_classifier': RandomForestClassifier(max_features=57, n_estimators=512, n_jobs=1,\n",
      "                       random_state=1, warm_start=True)}, 3: {'model_id': 3, 'rank': 2, 'cost': 0.21703296703296704, 'ensemble_weight': 0.26, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8cd8b5e310>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c65c9e040>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8cd87d0820>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage=0.6278970059064464, solver='lsqr',\n",
      "                           tol=0.00010463573132282596)}, 4: {'model_id': 4, 'rank': 3, 'cost': 0.2417582417582418, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4d8a1cd0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4af27fa0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c484178e0>, 'sklearn_classifier': LinearSVC(C=6.395900616857626, dual=False, intercept_scaling=1.0,\n",
      "          random_state=1, tol=0.00016419370701353068)}, 12: {'model_id': 12, 'rank': 4, 'cost': 0.26648351648351654, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4fda4c70>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4fb61ca0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4fb615e0>, 'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=12, min_samples_leaf=2,\n",
      "                       min_samples_split=3, n_estimators=512, n_jobs=1,\n",
      "                       random_state=1, warm_start=True)}, 14: {'model_id': 14, 'rank': 5, 'cost': 0.228021978021978, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4af167c0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4d435700>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4da3b850>, 'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=134, min_samples_leaf=18,\n",
      "                       min_samples_split=3, n_estimators=512, n_jobs=1,\n",
      "                       random_state=1, warm_start=True)}, 23: {'model_id': 23, 'rank': 6, 'cost': 0.2939560439560439, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4fb18d60>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4d85b5b0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4d85b820>, 'sklearn_classifier': KNeighborsClassifier(n_neighbors=4, weights='distance')}, 28: {'model_id': 28, 'rank': 7, 'cost': 0.3489010989010989, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4af05910>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8cd88253a0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4d4af1f0>, 'sklearn_classifier': BernoulliNB(alpha=0.011056975175744176)}, 32: {'model_id': 32, 'rank': 8, 'cost': 0.21703296703296704, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c45baafd0>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4842bfd0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4da32b20>, 'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=44, min_samples_leaf=4,\n",
      "                       min_samples_split=3, n_estimators=512, n_jobs=1,\n",
      "                       random_state=1, warm_start=True)}, 38: {'model_id': 38, 'rank': 9, 'cost': 0.23351648351648346, 'ensemble_weight': 0.06, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c45f267c0>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c45cda7c0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c45cda730>, 'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=13, min_samples_split=5,\n",
      "                       n_estimators=512, n_jobs=1, random_state=1,\n",
      "                       warm_start=True)}, 40: {'model_id': 40, 'rank': 10, 'cost': 0.2362637362637363, 'ensemble_weight': 0.02, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4d5d25b0>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4ab77a90>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4ab77dc0>, 'sklearn_classifier': LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n",
      "                           tol=0.00435539193714302)}, 48: {'model_id': 48, 'rank': 11, 'cost': 0.21153846153846156, 'ensemble_weight': 0.1, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4fb18220>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4b05b490>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4d625040>, 'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=35, min_samples_leaf=6,\n",
      "                       min_samples_split=3, n_estimators=512, n_jobs=1,\n",
      "                       random_state=1, warm_start=True)}, 52: {'model_id': 52, 'rank': 12, 'cost': 0.2417582417582418, 'ensemble_weight': 0.04, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c48417610>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4d5a43d0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4d885fa0>, 'sklearn_classifier': RandomForestClassifier(bootstrap=False, max_features=4, min_samples_leaf=7,\n",
      "                       min_samples_split=12, n_estimators=512, n_jobs=1,\n",
      "                       random_state=1, warm_start=True)}, 55: {'model_id': 55, 'rank': 13, 'cost': 0.20879120879120883, 'ensemble_weight': 0.12, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4ad07a60>, 'balancing': Balancing(random_state=1), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c4d8a13d0>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c4d885d00>, 'sklearn_classifier': LinearSVC(C=16.910805013540024, dual=False, intercept_scaling=1.0,\n",
      "          random_state=1, tol=0.021216042531179893)}, 56: {'model_id': 56, 'rank': 14, 'cost': 0.3571428571428571, 'ensemble_weight': 0.18, 'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f8c4d3ceee0>, 'balancing': Balancing(random_state=1, strategy='weighting'), 'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f8c52395550>, 'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f8c523955e0>, 'sklearn_classifier': LinearSVC(C=0.101051184027903, class_weight='balanced', dual=False,\n",
      "          intercept_scaling=1.0, random_state=1, tol=0.006691404256533949)}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "X_train = new_x[train_mask]\n",
    "X_val = new_x[valid_mask]\n",
    "X_test = new_x[test_mask]\n",
    "X_train_val = new_x[train_valid_idx]\n",
    "\n",
    "y_train = labels[train_mask]\n",
    "y_val = labels[valid_mask]\n",
    "y_train_val = labels[train_valid_idx]\n",
    "y_test = labels[test_mask]\n",
    "\n",
    "\n",
    "# Initialize AutoSklearn classifier\n",
    "automl = AutoSklearnClassifier(\n",
    "    time_left_for_this_task=120, # You can change this as per your requirements\n",
    "    per_run_time_limit=30,       # You can change this as per your requirements\n",
    "    n_jobs=8,                    # Use all available cores\n",
    "    memory_limit=6144\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "automl.fit(X_train_val, y_train_val, dataset_name='classification_dataset')\n",
    "\n",
    "# Validation \n",
    "y_val_pred = automl.predict(X_val)\n",
    "val_accuracy = np.mean(y_val_pred == y_val)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
    "\n",
    "# Test\n",
    "y_test_pred = automl.predict(X_test)\n",
    "test_accuracy = np.mean(y_test_pred == y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Get the final ensemble constructed by auto-sklearn\n",
    "print(automl.show_models())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091db61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
